秒杀系统中，瞬时流量非常大，库存只有一份,所有人会在集中的时间读写这些数据，读写冲突，锁非常严重，
这是秒杀业务难得的地方，从架构上怎么优化秒杀业务呢?
一般web应用的架构是这样的
....................................................................................................................
| 客户端(web浏览器/app) | ---> | 网关层(nginx) | ---> | 服务层(后端分布式应用) | ---> | 数据层(缓存,数据库mysql等) |
....................................................................................................................
这个图虽然简单，但能形象的说明大流量高并发的秒杀业务架构。
客户端(web浏览器/app)会执行一些js代码，发起请求
网关层会把请求反向代理到后端服务
服务层处理业务请求
数据层,最终的库存数据在这里，比如数据库或缓存

优化细节:
1,客户端(web浏览器/app)层
用户在秒杀开始之前，会对详情页做大量的刷新操作。所以将详情页部署到CDN上，CDN将详情页做静态化处理。
这样其实用户访问的静态页的html已经不在秒杀系统上了，而在CDN节点上。
一般的秒杀页面,通常会有查询,秒杀这样的操作按钮，当点击"查询"按钮后，如果系统卡，进度慢，作为用户，可能会再次点击"查询"，
诸如这样的重复操作，平白无故的增加了系统负担，这里的优化
a,产品层面，用户点击"查询"或"秒杀"后，按钮可置非或置非几秒,可在web交互页面上禁止用户重复提交请求
b,前端web，js代码中可限制用户在x秒内置提交一次请求,app中，也可做类似的事情，x秒才向后端发送一次请求
这就是将请求尽量拦截在系统上游，越上游越好，浏览器层，APP层就给拦住，这样就能挡住80%+的请求，这种办法只能拦住普通用户（但99%的用户是普通用户）。
部分用户，firebug抓请求包，http请求是啥就知道了，写for循环调用此http接口，这部分请求怎么处理?(见下面网关层的优化)

2,网关层(nginx)
怎么防止抓请求包，for循环调用请求，有去重依据么?这类业务都需要登录，用uid即可。
在网关层，对uid进行请求计数和去重，甚至不需要统一存储计数，直接网关层内存存储（这样计数会不准，但最简单）。
一个uid，5秒只准透过1个请求，这样又能拦住99%的for循环请求。
对于业务请求,与个人无关的请求，还可做页面缓存，x秒内到达网关层的请求，均返回同一份缓存页面。
如此限流，既能保证用户有良好的用户体验（没有返回404）,又能保证系统的健壮性（利用页面缓存，把请求拦截在网关层了)
如果峰值请求非常大，比如上千万，这里的网关层可以加机器扩容，如果机器不够，可在此层抛弃请求，比如抛弃50%的请求,
也就是50%的请求直接返回稍后再试,原则是要保护系统，不让所有用户请求都失败。

3,服务层(后端分布式应用)
服务层对于写请求的拦截,可通过请求队列的方式来进行拦截。
对于写请求，做请求队列，每次只透过有限的写请求去业务处理，访问数据层(比如下单，支付这样的写业务)
比如只有1w部手机，只透过2k个下单请求去db,如果成功，再放下一批，如果库存没了则队列里的写请求全部返回"已销完"，
如果写请求非常多，比如100w,但可能库存就1w的手机，都把请求方队列里也没啥意义，可以队列里面请求到达2w或3w后，
后面的请求都直接返回"已销完"就好了,而不再放到队列里。这里队列是服务层统一的一个队列？还是每个提供服务的服务器各一个队列？
可以不用统一一个队列，这样的话每个服务透过更少量的请求（总票数/服务个数），这样简单。统一一个队列又复杂了。
对于读请求，cache抗，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题的。
如此限流，只有非常少的写请求，和非常少的读缓存miss的请求会透到数据层去，又有99.9%的请求被拦住了。
当然，服务层还可以做业务规则上的一些优化。这个是结合业务来的，具体情况具体分析。

对于后端如何防止重复提交，就是保证相同的请求在同一时间只能被处理一次。
方法:前端进入页面时,获取服务器端产生的一个唯一token,提交时把token提交过去,服务端在处理请求时判断token是否存在,是否与后端服务的token相等，
若存在且相等,则销毁掉服务端的此token,进行后续正常业务逻辑,如不存在或不相等,则报错重复提交。

4,数据层(缓存,数据库mysql等)
客户端拦截了80%，网关层拦截了99.9%并做了页面缓存，服务层又做了写请求队列与数据缓存，每次透到数据库层的请求都是可控的。
db基本就没什么压力了，单机也能扛得住。

对于秒杀系统,尽量将请求拦截在系统上游（越上游越好）,读多写少的场景多使用缓存（缓存抗读压力）
客户端(web浏览器/app)：做限速
站点层：按照uid做限速，做页面缓存
服务层：按照业务做写请求队列控制流量，做读数据缓存
数据层：无压力


