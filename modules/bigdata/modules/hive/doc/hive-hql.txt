------------------------------hive hql-------------------------
hive命令行交互
hive –f  /root/shell/hive-script.sql（适合多语句）
vi hive_script.sql
    select * from t1;
    select count(*) from t1;
hive -S -f /root/shell/hive-script.sql（和静音模式-S联合使用不会显示mapreduct的操作过程）

hive -e 'select * from t1'
hive -S -e 'select * from t1'           #静音模式
hive -e 'select * from t1'  > test.txt  #查询后结果保存到test.txt

-------------------------
#直接使用hive交互

查看数据库
hive> show databases;

创建数据库
hive> create database test;

使用哪个数据库
hive> use default;

创建表：
hive> CREATE TABLE pokes (foo INT, bar STRING);

hive>  CREATE TABLE data_tmp (userid INT,rating INT,unixtime STRING)
       ROW FORMAT DELIMITED
       FIELDS TERMINATED BY '\t'
       STORED AS TEXTFILE;
创建一个新表，结构与其他一样
hive> create table new_table like records;

创建分区表：
hive> create table logs(ts bigint,line string) partitioned by (dt String,country String);

加载分区表数据：
hive> load data local inpath '/home/hadoop/input/hive/partitions/file1' into table logs partition (dt='2001-01-01',country='GB');

加载DFS数据 ，同时给定分区信息
hive> load data inpath '/user/data/d2.txt'  overwrite into table logs partition (dt='2001-01-01',country='GB');

展示表中有多少分区：
hive> show partitions logs;

展示所有表：
hive> SHOW TABLES;
        lists all the tables
hive> SHOW TABLES '.*s';

lists all the table that end with 's'. The pattern matching follows Java regular
expressions. Check out this link for documentation

显示表的结构信息
hive> DESCRIBE invites;
        shows the list of columns

更新表的名称：
hive> ALTER TABLE source RENAME TO target;

添加新一列
hive> ALTER TABLE invites ADD COLUMNS (new_col2 INT COMMENT 'a comment');

删除表：
hive> DROP TABLE records;

删除表中数据，但要保持表的结构定义
hive> dfs -rmr /user/hive/warehouse/records;

从本地文件加载数据：
hive> LOAD DATA LOCAL INPATH '/home/hadoop/input/ncdc/micro-tab/sample.txt' OVERWRITE INTO TABLE records;

显示所有函数：
hive> show functions;

查看函数用法：
hive> describe function substr;

查看数组、map、结构
hive> select col1[0],col2['b'],col3.c from complex;

内连接：
hive> SELECT sales.*, things.* FROM sales JOIN things ON (sales.id = things.id);

查看hive为某个查询使用多少个MapReduce作业
hive> Explain SELECT sales.*, things.* FROM sales JOIN things ON (sales.id = things.id);

外连接：
hive> SELECT sales.*, things.* FROM sales LEFT OUTER JOIN things ON (sales.id = things.id);
hive> SELECT sales.*, things.* FROM sales RIGHT OUTER JOIN things ON (sales.id = things.id);
hive> SELECT sales.*, things.* FROM sales FULL OUTER JOIN things ON (sales.id = things.id);

in查询：Hive不支持，但可以使用LEFT SEMI JOIN
hive> SELECT * FROM things LEFT SEMI JOIN sales ON (sales.id = things.id);

Map连接：Hive可以把较小的表放入每个Mapper的内存来执行连接操作
hive> SELECT /*+ MAPJOIN(things) */ sales.*, things.* FROM sales JOIN things ON (sales.id = things.id);

INSERT OVERWRITE TABLE ..SELECT：新表预先存在
hive> FROM records2
    > INSERT OVERWRITE TABLE stations_by_year SELECT year, COUNT(DISTINCT station) GROUP BY year
    > INSERT OVERWRITE TABLE records_by_year SELECT year, COUNT(1) GROUP BY year
    > INSERT OVERWRITE TABLE good_records_by_year SELECT year, COUNT(1) WHERE temperature != 9999 AND (quality = 0 OR quality = 1 OR quality = 4 OR quality = 5 OR quality = 9) GROUP BY year;

CREATE TABLE ... AS SELECT：新表表预先不存在
hive>CREATE TABLE target AS SELECT col1,col2 FROM source;

创建视图：
hive> CREATE VIEW valid_records AS SELECT * FROM records2 WHERE temperature !=9999;

查看视图详细信息：
hive> DESCRIBE EXTENDED valid_records;

将查询数据输出至DFS目录
hive> INSERT OVERWRITE DIRECTORY '/tmp/hdfs_out' SELECT a.* FROM invites a WHERE a.ds='';

将查询结果输出至本地目录
hive> INSERT OVERWRITE LOCAL DIRECTORY '/tmp/local_out' SELECT a.* FROM pokes a;

将一个表的统计结果插入另一个表中
hive> FROM invites a INSERT OVERWRITE TABLE events SELECT a.bar, count(1) WHERE a.foo > 0 GROUP BY a.bar;
hive> INSERT OVERWRITE TABLE events SELECT a.bar, count(1) FROM invites a WHERE a.foo > 0 GROUP BY a.bar;

------------------------------------------------------------------