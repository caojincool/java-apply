---------------------kafka安装-------------------
1,下载kafka
  wget -q wget -q http://apache.fayea.com/kafka/0.8.2.2/kafka_2.9.1-0.8.2.2.tgz
2,压缩后微调
  tar -xzvf kafka_2.9.1-0.8.2.2.tgz
  rm kafka_2.9.1-0.8.2.2.tgz
  kafka默认开启jvm压缩指针，但只是64位jvm支持，32位jvm需要修改./bin/kafka-run-class.sh文件,去除-XX:+UseCompressedOops参数
3,启动kafka应用
  启动zookeeper  bin/zookeeper-server-start.sh config/zookeeper.properties &
  启动kafka      bin/kafka-server-start.sh config/server.properties &
  新建一个主题(topic),创建一个名为test的topic，只有一个分区和一个备份
  bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
  显示topic列表
  bin/kafka-topics.sh --list --zookeeper localhost:2181
  删除topic
  #需要在server.properties配置中添加delete.topic.enable=true
  bin/kafka-topics.sh --zookeeper nlocalhost:2181 --delete --topic topic1
4,单机连通性测试
  运行producer  bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
  运行consumer  bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
  在producer端输入字符串并回车，查看consumer端是否显示
5,分布式连通性测试
  server1 192.168.1.2 zookeeper,kafka,producer
  server2 192.168.1.3 consumer
  运行server1机器上的zookeeper,kafka,producer
  bin/zookeeper-server-start.sh config/zookeeper.properties &
  bin/kafka-server-start.sh config/server.properties &
  bin/kafka-console-producer.sh --broker-list 192.168.1.2:9092 --topic test
  运行server2的consumer
  bin/kafka-console-consumer.sh --zookeeper 192.168.1.2:2181 --topic test --from-beginning
  在server1上的producer的console端输入字符串并回车，查看server2上的consumer端是否显示
  如果consumer端报Connection refused错误,修改kafka配置文件server.properties设置host.name=192.168.1.2
--------------------------------------------------------
